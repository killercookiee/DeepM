{"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/killercookiee/DeepM/blob/main/DeepM_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":99417,"status":"ok","timestamp":1729269161069,"user":{"displayName":"Praneshraj T.N.D.","userId":"07236036155328031414"},"user_tz":-120},"id":"6lUNeF2kXNDZ","outputId":"9bbb58bd-5c26-402d-c20c-75314d6a0a12"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'medical-image-segmentation'...\n","remote: Enumerating objects: 1109, done.\u001b[K\n","remote: Counting objects: 100% (20/20), done.\u001b[K\n","remote: Compressing objects: 100% (18/18), done.\u001b[K\n","remote: Total 1109 (delta 1), reused 18 (delta 1), pack-reused 1089 (from 1)\u001b[K\n","Receiving objects: 100% (1109/1109), 2.24 GiB | 31.39 MiB/s, done.\n","Resolving deltas: 100% (15/15), done.\n","Updating files: 100% (1061/1061), done.\n"]}],"source":["!git clone https://github.com/AMIN-HASSAIRI/medical-image-segmentation.git"]},{"cell_type":"markdown","metadata":{"id":"oKaWA0iPxbzb"},"source":["Understanding the File format\n","\n","Neuroimaging Informatics Technology Initiative\n","NIfTI is designed to handle 3D (volume) and 4D (time-series) data, which is common in brain imaging, especially for functional MRI (fMRI) studies\n","NIfTI files can also be stored in a compressed .nii.gz format to save disk space\n","\n","4 D --> Height + Width + Depth + Time\n","\n","We are working with pairs of files. Example\n","1. Say MRI scan of heart\n","2. Corresponding segmentation mask file -> i.e. a label that marks different part of the image, like heart chambers, valves, etc\n","\n","Possibly\n","\n","patient001_4d.nii.gz -> 4D file (Sequence of 3d images over time), not used for segmentation\n","patient001_frame01.nii.gz -> A single 2D slice of the 3D MRI data. Image file used for traning the model\n","patient001_frame01_gt.nii.gz -> It contains labels marking the regions of interest in the image"]},{"cell_type":"markdown","metadata":{"id":"SOAhFVCjdHMa"},"source":["# Imports"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":8869,"status":"ok","timestamp":1729269169931,"user":{"displayName":"Praneshraj T.N.D.","userId":"07236036155328031414"},"user_tz":-120},"id":"VOrlC9D4dHMb"},"outputs":[],"source":["%pip install opencv-python --quiet\n","%pip install scikit-image --quiet"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1529,"status":"ok","timestamp":1729269171452,"user":{"displayName":"Praneshraj T.N.D.","userId":"07236036155328031414"},"user_tz":-120},"id":"039VDvIRdHMc"},"outputs":[],"source":["import os\n","import numpy as np\n","import nibabel as nib\n","import matplotlib.pyplot as plt\n","from skimage.transform import resize\n","import cv2\n","\n","import shutil"]},{"cell_type":"markdown","metadata":{"id":"Ov5A4i_zdHMc"},"source":["# Original Training Data"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1729269171453,"user":{"displayName":"Praneshraj T.N.D.","userId":"07236036155328031414"},"user_tz":-120},"id":"i4FHnXBbEmUC"},"outputs":[],"source":["def select_training_data(dataset_dir):\n","    data_anomolies = ['038', '085', '057', '089', '100']\n","\n","    training_data_list = {}\n","    for k in ['training']:\n","\n","        subset_dir = os.path.join(dataset_dir, k)\n","        training_data_list[k] = []\n","\n","        for patient in sorted(os.listdir(subset_dir)):\n","\n","            patient_dir = os.path.join(subset_dir, patient)\n","\n","            # Skip files that are not directories\n","            if not os.path.isdir(patient_dir):\n","                continue\n","\n","            for file in sorted(os.listdir(patient_dir)):\n","                if file[-8] == 't' and file[-21:-18] not in data_anomolies:\n","\n","                    image_name = '{0}/{1}_frame{2}.nii.gz'.format(patient_dir, patient, file[-12:-10])\n","                    segt_name = '{0}/{1}_frame{2}_gt.nii.gz'.format(patient_dir, patient, file[-12:-10])\n","\n","                    if os.path.exists(image_name) and os.path.exists(segt_name):\n","                        training_data_list[k] += [[image_name, segt_name, patient]]\n","\n","    return training_data_list\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":263},"executionInfo":{"elapsed":584,"status":"error","timestamp":1729269172032,"user":{"displayName":"Praneshraj T.N.D.","userId":"07236036155328031414"},"user_tz":-120},"id":"HCg5EE14auSj","outputId":"57df0fb0-5307-4f8d-c99a-2a7462374fec"},"outputs":[],"source":["original_training_data_list = select_training_data(\"./medical-image-segmentation/dataset\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":21,"status":"aborted","timestamp":1729269172033,"user":{"displayName":"Praneshraj T.N.D.","userId":"07236036155328031414"},"user_tz":-120},"id":"57gRcyekyekq"},"outputs":[],"source":["original_training_data_list"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":21,"status":"aborted","timestamp":1729269172034,"user":{"displayName":"Praneshraj T.N.D.","userId":"07236036155328031414"},"user_tz":-120},"id":"7ykZixgwdHMe"},"outputs":[],"source":["def select_testing_data(dataset_dir):\n","    testing_data_list = {}\n","\n","    for k in ['testing']:\n","        subset_dir = os.path.join(dataset_dir, k)\n","        testing_data_list[k] = []\n","\n","        for patient in sorted(os.listdir(subset_dir)):\n","\n","            patient_dir = os.path.join(subset_dir, patient)\n","\n","            # Skip files that are not directories\n","            if not os.path.isdir(patient_dir):\n","                continue\n","\n","            for file in sorted(os.listdir(patient_dir)):\n","                if file[-8] != 'd' and file[-8] != 'I':\n","\n","                    image_name = '{0}/{1}_frame{2}.nii.gz'.format(patient_dir, patient, file[-12:-10])\n","                    segt_name = '{0}/{1}_frame{2}_gt.nii.gz'.format(patient_dir, patient, file[-12:-10])\n","\n","                    if os.path.exists(image_name) and os.path.exists(segt_name):\n","                        testing_data_list[k] += [[image_name, segt_name, patient]]\n","\n","    return testing_data_list\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":21,"status":"aborted","timestamp":1729269172035,"user":{"displayName":"Praneshraj T.N.D.","userId":"07236036155328031414"},"user_tz":-120},"id":"ViHCJTamdHMf"},"outputs":[],"source":["original_testing_data_list = select_testing_data(\"./medical-image-segmentation/dataset\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":21,"status":"aborted","timestamp":1729269172036,"user":{"displayName":"Praneshraj T.N.D.","userId":"07236036155328031414"},"user_tz":-120},"id":"cIbpPbKKdHMf"},"outputs":[],"source":["original_testing_data_list"]},{"cell_type":"markdown","metadata":{"id":"o3-r7NikdHMg"},"source":["# Image Analysis"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":22,"status":"aborted","timestamp":1729269172037,"user":{"displayName":"Praneshraj T.N.D.","userId":"07236036155328031414"},"user_tz":-120},"id":"18xgZDGqdHMg"},"outputs":[],"source":["# Analyzing the data\n","\n","def analyze_image_properties(training_data_list):\n","    aspect_ratios = []\n","    widths = []\n","    heights = []\n","    resolutions = []\n","    pixel_sizes = []\n","    slice_counts = []\n","\n","    # Loop through each file in training_data_list (ignoring the segmentation files)\n","    for data in training_data_list['training']:\n","        image_file = data[0]  # Use the image file, not the segmentation file\n","\n","        # Load the NIfTI file\n","        img = nib.load(image_file)\n","        img_data = img.get_fdata()\n","        img_shape = img_data.shape\n","\n","        # Analyze shape and pixel sizes\n","        if len(img_shape) >= 2:\n","            width = img_shape[0]\n","            height = img_shape[1]\n","            depth = img_shape[2] if len(img_shape) > 2 else 1  # Number of slices or depth\n","\n","            # Aspect ratio (width to height)\n","            aspect_ratio = width / height\n","            aspect_ratios.append(aspect_ratio)\n","\n","            # Resolution (total number of pixels in 2D)\n","            resolution = width * height\n","            resolutions.append(resolution)\n","\n","            # Widths and heights\n","            widths.append(width)\n","            heights.append(height)\n","\n","            # Slice count (for 3D images)\n","            slice_counts.append(depth)\n","\n","        # Voxel size (physical dimensions of each voxel)\n","        voxel_size = img.header.get_zooms()  # Tuple (x_size, y_size, z_size)\n","        pixel_sizes.append(voxel_size)\n","\n","    return aspect_ratios, widths, heights, resolutions, pixel_sizes, slice_counts\n","\n","\n","# Analyze the training data\n","aspect_ratios, widths, heights, resolutions, pixel_sizes, slice_counts = analyze_image_properties(original_training_data_list)\n","\n","# Plot the results\n","def plot_analysis(aspect_ratios, widths, heights, resolutions, pixel_sizes, slice_counts):\n","    fig, ax = plt.subplots(2, 3, figsize=(12, 10))\n","\n","    # Aspect Ratio\n","    ax[0, 0].hist(aspect_ratios, bins=20, color='blue', alpha=0.7)\n","    ax[0, 0].set_title(\"Aspect Ratio Distribution\")\n","    ax[0, 0].set_xlabel(\"Aspect Ratio (Width/Height)\")\n","    ax[0, 0].set_ylabel(\"Frequency\")\n","\n","    # Width\n","    ax[0, 1].hist(widths, bins=20, color='grey', alpha=0.7)\n","    ax[0, 1].set_title(\"Width Distribution\")\n","    ax[0, 1].set_xlabel(\"Width\")\n","    ax[0, 1].set_ylabel(\"Frequency\")\n","\n","    # Height\n","    ax[0, 2].hist(heights, bins=20, color='grey', alpha=0.7)\n","    ax[0, 2].set_title(\"Height Distribution\")\n","    ax[0, 2].set_xlabel(\"Height\")\n","    ax[0, 2].set_ylabel(\"Frequency\")\n","\n","    # Resolution\n","    ax[1, 0].hist(resolutions, bins=20, color='green', alpha=0.7)\n","    ax[1, 0].set_title(\"Resolution Distribution\")\n","    ax[1, 0].set_xlabel(\"Resolution (Width x Height)\")\n","    ax[1, 0].set_ylabel(\"Frequency\")\n","\n","    # Pixel Size\n","    pixel_sizes_arr = np.array(pixel_sizes)  # Convert list of tuples to numpy array\n","    ax[1, 1].hist(pixel_sizes_arr[:, 0], bins=20, color='orange', alpha=0.7, label='X-dim')\n","    ax[1, 1].hist(pixel_sizes_arr[:, 1], bins=20, color='purple', alpha=0.5, label='Y-dim')\n","    ax[1, 1].set_title(\"Pixel Size Distribution\")\n","    ax[1, 1].set_xlabel(\"Pixel Size (in mm)\")\n","    ax[1, 1].set_ylabel(\"Frequency\")\n","    ax[1, 1].legend()\n","\n","    # Slice Count (number of slices in the depth dimension)\n","    ax[1, 2].hist(slice_counts, bins=20, color='red', alpha=0.7)\n","    ax[1, 2].set_title(\"Slice Count Distribution\")\n","    ax[1, 2].set_xlabel(\"Number of Slices\")\n","    ax[1, 2].set_ylabel(\"Frequency\")\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","# Plot the analysis\n","plot_analysis(aspect_ratios, widths, heights, resolutions, pixel_sizes, slice_counts)"]},{"cell_type":"markdown","metadata":{"id":"aAolkweCdHMi"},"source":["# Data Standardization"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":21,"status":"aborted","timestamp":1729269172037,"user":{"displayName":"Praneshraj T.N.D.","userId":"07236036155328031414"},"user_tz":-120},"id":"4xtiaVucdHMi"},"outputs":[],"source":["def load_nifti_image(nifti_file):\n","    \"\"\"Load NIfTI image and return image data.\"\"\"\n","    img = nib.load(nifti_file)\n","    return img.get_fdata()\n","\n","def normalize_image(img_data):\n","    \"\"\"Normalize the image pixel values to [0, 1] range.\"\"\"\n","    img_min = np.min(img_data)\n","    img_max = np.max(img_data)\n","    return (img_data - img_min) / (img_max - img_min)\n","\n","def standardize_image(img_data):\n","    \"\"\"Standardize the image to have mean=0 and std=1.\"\"\"\n","    mean = np.mean(img_data)\n","    std = np.std(img_data)\n","    return (img_data - mean) / std\n","\n","def pad_to_aspect_ratio(img_data, target_aspect_ratio, padding_value=0):\n","    \"\"\"Pad image to match the target aspect ratio.\"\"\"\n","    h, w = img_data.shape[:2]\n","    current_aspect_ratio = w / h\n","    if current_aspect_ratio == target_aspect_ratio:\n","        return img_data  # No padding needed\n","\n","    if current_aspect_ratio < target_aspect_ratio:\n","        # Pad width\n","        new_width = int(h * target_aspect_ratio)\n","        pad_left = (new_width - w) // 2\n","        img_data = np.pad(img_data, ((0, 0), (pad_left, new_width - w - pad_left)),\n","                          constant_values=padding_value)\n","    else:\n","        # Pad height\n","        new_height = int(w / target_aspect_ratio)\n","        pad_top = (new_height - h) // 2\n","        img_data = np.pad(img_data, ((pad_top, new_height - h - pad_top), (0, 0)),\n","                          constant_values=padding_value)\n","\n","    return img_data\n","\n","def resize_image(img_data, target_size=(256, 256)):\n","    \"\"\"Resize the image to the target size.\"\"\"\n","    from skimage.transform import resize\n","    return resize(img_data, target_size, anti_aliasing=True, preserve_range=True)\n","\n","\n","\n","\n","def combine_slices_into_nifti(img_file, seg_file, save_folder, frame_label):\n","    \"\"\"Combine image and segmentation slices into a single 3D NIfTI volume.\"\"\"\n","\n","    # Load image and segmentation data\n","    img_data = nib.load(img_file).get_fdata()\n","    seg_data = nib.load(seg_file).get_fdata()\n","\n","    # Ensure they have the same dimensions\n","    if img_data.shape != seg_data.shape:\n","        raise ValueError(f\"Image and segmentation dimensions do not match for {img_file}.\")\n","\n","    # Create NIfTI image object\n","    affine = nib.load(img_file).affine  # Re-use affine from original NIfTI file\n","    combined_nifti = nib.Nifti1Image(img_data, affine)\n","    combined_seg_nifti = nib.Nifti1Image(seg_data, affine)\n","\n","    # Save combined 3D NIfTI image\n","    patient_id = os.path.basename(img_file).split('_')[0]  # Extract patient ID from filename\n","    output_image_file = os.path.join(save_folder, f'{patient_id}_{frame_label}.nii.gz')\n","    output_seg_file = os.path.join(save_folder, f'{patient_id}_{frame_label}_gt.nii.gz')\n","\n","    nib.save(combined_nifti, output_image_file)\n","    nib.save(combined_seg_nifti, output_seg_file)\n","\n","def get_second_frame(patient_data):\n","    \"\"\"Identify the second frame that is not frame01.\"\"\"\n","    for frame in patient_data:\n","        if \"frame01\" not in frame[0]:\n","            return frame\n","    return None  # In case no second frame is found\n","\n","def process_patient_data(patient_frames, save_dir):\n","    \"\"\"Process and transform the patient data for both frames.\"\"\"\n","    img_file_1, seg_file_1, patient_id = patient_frames[0]  # Frame01\n","    second_frame = get_second_frame(patient_frames)  # Identify the second frame\n","\n","    if second_frame:\n","        img_file_2, seg_file_2, _ = second_frame  # The second frame\n","\n","        # Create patient folder\n","        patient_folder = os.path.join(save_dir, patient_id)\n","        os.makedirs(patient_folder, exist_ok=True)\n","\n","        # Transform both frames and their corresponding segmentation files\n","        combine_slices_into_nifti(img_file_1, seg_file_1, patient_folder, \"frame01\")  # Frame01\n","        combine_slices_into_nifti(img_file_2, seg_file_2, patient_folder, \"frame02\")  # Second Frame\n","\n","def create_new_training_dataset(training_data_list, save_dir):\n","    \"\"\"Create a new dataset by transforming and combining patient slices.\"\"\"\n","    if not os.path.exists(save_dir):\n","        os.makedirs(save_dir)\n","\n","    # Group data by patient\n","    patient_dict = {}\n","    for img_file, seg_file, patient_id in training_data_list['training']:\n","        if patient_id not in patient_dict:\n","            patient_dict[patient_id] = []\n","        patient_dict[patient_id].append((img_file, seg_file, patient_id))\n","\n","    # Process each patient\n","    for patient_data in patient_dict.values():\n","        process_patient_data(patient_data, save_dir)\n","\n","def create_new_testing_dataset(testing_data_list, save_dir):\n","    \"\"\"Create a new dataset by transforming and combining patient slices.\"\"\"\n","    if not os.path.exists(save_dir):\n","        os.makedirs(save_dir)\n","\n","    # Group data by patient\n","    patient_dict = {}\n","    for img_file, seg_file, patient_id in testing_data_list['testing']:\n","        if patient_id not in patient_dict:\n","            patient_dict[patient_id] = []\n","        patient_dict[patient_id].append((img_file, seg_file, patient_id))\n","\n","    # Process each patient\n","    for patient_data in patient_dict.values():\n","        process_patient_data(patient_data, save_dir)\n","\n","\n","# Example usage\n","training_save_dir = './medical-image-segmentation/new_dataset/training'\n","create_new_training_dataset(original_training_data_list, training_save_dir)\n","\n","testing_save_dir = './medical-image-segmentation/new_dataset/testing'\n","create_new_testing_dataset(original_testing_data_list, testing_save_dir)"]},{"cell_type":"markdown","metadata":{"id":"B2HyEmSBdHMj"},"source":["# New Standardized Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":21,"status":"aborted","timestamp":1729269172038,"user":{"displayName":"Praneshraj T.N.D.","userId":"07236036155328031414"},"user_tz":-120},"id":"r2hQnYf3dHMj"},"outputs":[],"source":["def select_new_training_data(dataset_dir):\n","    data_anomolies = ['038', '085', '057', '089', '100']\n","\n","    training_data_list = {}\n","    for k in ['training']:\n","\n","        subset_dir = os.path.join(dataset_dir, k)\n","        training_data_list[k] = []\n","\n","        for patient in sorted(os.listdir(subset_dir)):\n","\n","            patient_dir = os.path.join(subset_dir, patient)\n","\n","            # Skip files that are not directories\n","            if not os.path.isdir(patient_dir):\n","                continue\n","\n","            for file in sorted(os.listdir(patient_dir)):\n","                if file[-8] == 't' and file[-21:-18] not in data_anomolies:\n","\n","                    image_name = '{0}/{1}_frame{2}.nii.gz'.format(patient_dir, patient, file[-12:-10])\n","                    segt_name = '{0}/{1}_frame{2}_gt.nii.gz'.format(patient_dir, patient, file[-12:-10])\n","\n","                    if os.path.exists(image_name) and os.path.exists(segt_name):\n","                        training_data_list[k] += [[image_name, segt_name, patient]]\n","\n","    return training_data_list\n","\n","\n","\n","def select_new_testing_data(dataset_dir):\n","    testing_data_list = {}\n","\n","    for k in ['testing']:\n","        subset_dir = os.path.join(dataset_dir, k)\n","        testing_data_list[k] = []\n","\n","        for patient in sorted(os.listdir(subset_dir)):\n","\n","            patient_dir = os.path.join(subset_dir, patient)\n","\n","            # Skip files that are not directories\n","            if not os.path.isdir(patient_dir):\n","                continue\n","\n","            for file in sorted(os.listdir(patient_dir)):\n","                if file[-8] != 'd' and file[-8] != 'I':\n","\n","                    image_name = '{0}/{1}_frame{2}.nii.gz'.format(patient_dir, patient, file[-12:-10])\n","                    segt_name = '{0}/{1}_frame{2}_gt.nii.gz'.format(patient_dir, patient, file[-12:-10])\n","\n","                    if os.path.exists(image_name) and os.path.exists(segt_name):\n","                        testing_data_list[k] += [[image_name, segt_name, patient]]\n","\n","    return testing_data_list\n","\n","\n","\n","training_data_list = select_new_training_data(\"/Users/killercookie/Main file/DeepM/medical-image-segmentation/new_dataset\")\n","testing_data_list = select_new_testing_data(\"/Users/killercookie/Main file/DeepM/medical-image-segmentation/new_dataset\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":22,"status":"aborted","timestamp":1729269172039,"user":{"displayName":"Praneshraj T.N.D.","userId":"07236036155328031414"},"user_tz":-120},"id":"aVNOSRXddHMk"},"outputs":[],"source":["#training_data_list"]},{"cell_type":"markdown","metadata":{"id":"iLxCoNh0xuZx"},"source":["# Data Visualization"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":22,"status":"aborted","timestamp":1729269172040,"user":{"displayName":"Praneshraj T.N.D.","userId":"07236036155328031414"},"user_tz":-120},"id":"jkpp98hpX2AC"},"outputs":[],"source":["import plotly.graph_objects as go  # Graph Objects module comprises visuals like Heatmaps, Figures, etc\n","from skimage.transform import resize\n","import nibabel as nib\n","import matplotlib.pyplot as plt\n","\n","def load_nifti_image(nifti_file):\n","    # Load the image using nibabel\n","    img = nib.load(nifti_file)\n","    img_data = img.get_fdata()  # Getting the actual image data as a numpy array\n","    return img_data\n","\n","# Function to resize image data to square dimensions\n","def resize_image(img_data, new_size=(128, 128)):  #3D image inputted, and each of its 2D slice is resized\n","    resized_img = np.zeros((new_size[0], new_size[1], img_data.shape[2]))  ## Create empty 3D array with the target size for each 2D slice\n","    for z in range(img_data.shape[2]):  # Loop over each slice of the 3D image\n","        resized_img[:, :, z] = resize(img_data[:, :, z], new_size, anti_aliasing=True)  # Resizing each 2D slice\n","    return resized_img\n","\n","# To visualise MRI image and mask side by side\n","def visualize_2d_image_and_mask(image_data, mask_data, title=\"MRI and Mask Visualization\", new_size=(128, 128)):\n","    resized_image_data = resize_image(image_data, new_size=new_size)\n","    resized_mask_data = resize_image(mask_data, new_size=new_size)\n","\n","    fig = go.Figure()\n","\n","    # Add MRI Image slices (left)\n","    for z in range(resized_image_data.shape[2]):\n","        fig.add_trace(go.Heatmap(\n","            z=resized_image_data[:, :, z],  # passs the 2D slice\n","            visible=(z == 0),  # Show first slice by default\n","            colorscale='Gray', # MRI slices are displayed in grayscale\n","            zmin=np.min(resized_image_data), zmax=np.max(resized_image_data),  # Dynamic scaling\n","            name=\"MRI Image\",\n","            showscale=False,\n","            xaxis='x1',  # Left side axis\n","            yaxis='y1'\n","        ))\n","\n","    # Add Segmentation mask slices (right)\n","    for z in range(resized_mask_data.shape[2]):\n","        fig.add_trace(go.Heatmap(\n","            z=resized_mask_data[:, :, z],  # Align MRI and Mask slices to same index\n","            visible=(z == 0),  # Show first slice by default\n","            colorscale='Reds', # Display masked slices in red color\n","            zmin=np.min(resized_mask_data), zmax=np.max(resized_mask_data),  # Dynamic scaling\n","            name=\"Segmentation Mask\",\n","            showscale=False,\n","            xaxis='x2',  # Right side axis\n","            yaxis='y2'\n","        ))\n","\n","    # Create step sliders for synchronized MRI and Mask slices\n","    steps = []\n","    num_slices = resized_image_data.shape[2]  # Assuming that both MRI and Mask have same number of slices\n","\n","    for z in range(num_slices):\n","        slice_step = dict(\n","            method=\"update\",\n","            args=[{\"visible\": [False] * num_slices * 2},  # Initially set all slices to invisible\n","                  {\"title\": f\"MRI and Mask Slice {z + 1}\"}],  # Update title to show slice number\n","        )\n","        # Set visibility to True for the corresponding MRI and Mask slices\n","        slice_step[\"args\"][0][\"visible\"][z] = True  # Make the MRI image slice visible\n","        slice_step[\"args\"][0][\"visible\"][num_slices + z] = True  # Make the mask slice visible\n","        steps.append(slice_step)\n","\n","    # Define a single slider for both MRI and Mask\n","    sliders = [dict(\n","        active=0,\n","        currentvalue={\"prefix\": \"Slice: \"},  # Display the current slice number\n","        pad={\"t\": 50},  # Padding from the top of the plot\n","        steps=steps  # Synchronized steps for MRI and Mask\n","    )]\n","\n","    # Define layout for side-by-side comparison\n","    fig.update_layout(\n","        sliders=sliders,\n","        title=title,\n","        xaxis=dict(domain=[0, 0.45], title=\"MRI Image\"),\n","        yaxis=dict(scaleanchor=\"x\", scaleratio=1),  # Ensure aspect ratio is square\n","        xaxis2=dict(domain=[0.55, 1], title=\"Segmentation Mask\"),\n","        yaxis2=dict(scaleanchor=\"x2\", scaleratio=1),\n","        height=500, width=800\n","    )\n","\n","    fig.show()\n","\n","# Function to visualize random training samples dynamically\n","def visualize_random_samples_side_by_side(data_list, data_type=\"Training\", num_samples=3, new_size=(128, 128)):\n","    for i in range(num_samples):\n","        random_idx = random.randint(0, len(data_list) - 1)\n","        print(f\"Visualizing {data_type} Dataset - Sample {random_idx}\")\n","        img_data = load_nifti_image(data_list[random_idx][0])  # Load MRI image data\n","        mask_data = load_nifti_image(data_list[random_idx][1])  # Load segmentation mask data\n","\n","\n","        # Making sure dimensions of the image and mask are aligned\n","        assert img_data.shape == mask_data.shape, \"Image and mask dimensions do not match!\"\n","\n","        # Visualize both the 2D MRI image and segmentation mask dynamically, side by side\n","        visualize_2d_image_and_mask(img_data, mask_data, title=f\"{data_type} Sample {random_idx}\", new_size=new_size)\n","\n","# Visualize 3 random training samples from the dataset, side by side\n","visualize_random_samples_side_by_side(training_data_list['training'], data_type=\"Training\", num_samples=3, new_size=(128, 128))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gLYvC1gTdHMl"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
